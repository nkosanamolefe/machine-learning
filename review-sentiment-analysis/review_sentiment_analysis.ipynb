{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LBzsAmyqaZqR"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "import nltk\n",
        "# nlrk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import word_tokenize\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data loading\n",
        "df = pd.read_csv('reviews.csv')"
      ],
      "metadata": {
        "id": "Z0NQjYxbboY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Cleaning\n",
        "def clean_text(text):\n",
        "  if isinstance(text, str):\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text) # remove punctuations\n",
        "    text = text.lower() # lowercase\n",
        "    tokens = word_tokenize(text)\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
        "    cleaned_text = ' '.join(filtered_tokens)\n",
        "    return text\n",
        "  return ''\n",
        "\n",
        "df['cleaned_comments'] = df['comments'].apply(clean_text)"
      ],
      "metadata": {
        "id": "IpsZTAV0EMrO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Preparation\n",
        "df = df[df['cleaned_comments'] != ''] # removing null reviews\n",
        "X = df['cleaned_comments']\n",
        "y = df['rating']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "kIAyNrO9Ejnw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Text Proprocessing\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "  tokens = word_tokenize(text)\n",
        "  filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
        "  return ' '.join(filtered_tokens)\n",
        "\n",
        "X_train = X_train.apply(preprocess_text)\n",
        "X_test = X_test.apply(preprocess_text)"
      ],
      "metadata": {
        "id": "BExK8vAMG0Go"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Training\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train_vec, y_train)"
      ],
      "metadata": {
        "id": "0WwOzCftHGqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Set Evaluation\n",
        "y_pred = model.predict(X_test_vec)\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "RYcWJsyVHS-4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}